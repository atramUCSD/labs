{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the instructions of this notebook to create all relevant directories and to load all relevant data into the correct places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os, sys\n",
    "import pymongo as pm\n",
    "import pandas as pd\n",
    "import socket\n",
    "import json\n",
    "import numpy as np\n",
    "import base64\n",
    "import importlib\n",
    "import time\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import mode\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# import utils\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "ratings_dir = os.path.join(plot_dir,'ratings')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "gallery_dir = os.path.abspath(os.path.join(proj_dir,'gallery'))\n",
    "if socket.gethostname() == 'nightingale':\n",
    "    feature_dir = os.path.abspath('/mnt/pentagon/photodraw/features/')\n",
    "else:\n",
    "    feature_dir = os.path.abspath(os.path.join(proj_dir,'features'))\n",
    "stims_gallery_dir = os.path.join(gallery_dir, 'stims')\n",
    "    \n",
    "meta_path = os.path.abspath(os.path.join(feature_dir, 'metadata_pixels.csv'))\n",
    "image_path = os.path.abspath(os.path.join(feature_dir, 'flattened_sketches_pixels.npy'))\n",
    "meta_path_fc6 = os.path.abspath(os.path.join(feature_dir, 'METADATA_sketch.csv'))\n",
    "image_path_fc6 = os.path.abspath(os.path.join(feature_dir, 'FEATURES_FC6_sketch_no-channel-norm.npy'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir,\n",
    "                                              sketch_dir,gallery_dir,feature_dir, \n",
    "                                              ratings_dir,stims_gallery_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "\n",
    "`ssh -fNL 27020:127.0.0.1:27017 jyang@cogtoolslab.org`  \n",
    "`ssh -fNL 27017:127.0.0.1:27017 jyang@cogtoolslab.org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "\n",
    "# this auth.txt file contains the password for the sketchloop user\n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) \n",
    "pswd = auth.values[0][0]\n",
    "decoderpswd = int(pswd[-1])\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import socket\n",
    "if socket.gethostname().split('_')[0]=='Justin':\n",
    "    conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27020')\n",
    "else:\n",
    "    conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017')\n",
    "db = conn['photodraw']\n",
    "coll = db['sketchy32']\n",
    "\n",
    "iterationName = 'livetest0'\n",
    "coll.distinct('iterationName')\n",
    "\n",
    "# get a sample: coll.find_one({'iterationName':iterationName})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K_responses = coll.find({\n",
    "            'iterationName':'livetest1', \n",
    "            'prolificID': {'$exists' : True},\n",
    "            'studyID': {'$exists' : True},\n",
    "            'sessionID': {'$exists' : True},\n",
    "            'eventType': 'rating-task'\n",
    "})\n",
    "K_responses = pd.DataFrame(K_responses)\n",
    "\n",
    "K_flags = coll.find({\n",
    "            'iterationName': 'livetest1',\n",
    "            'prolificID': {'$exists' : True},\n",
    "            'studyID': {'$exists' : True},\n",
    "            'sessionID': {'$exists' : True},\n",
    "            'eventType': 'trial-catches'\n",
    "})\n",
    "K_flags = pd.DataFrame(K_flags)\n",
    "\n",
    "# remove those who never completed the experiment\n",
    "dropped_out = set(K_responses.prolificID.unique()).difference(set(K_flags.prolificID.unique()))\n",
    "K_responses = K_responses[~K_responses.prolificID.isin(dropped_out)]\n",
    "\n",
    "# make map from prolificID to flags and use map to extend to K_responses\n",
    "id_to_flags = dict(zip(K_flags['prolificID'].values, K_flags[['failed_catches', 'num_failed','lazy_responder','repeat_offender']].values.tolist()))\n",
    "\n",
    "df1 = K_responses['prolificID'].map(id_to_flags)\n",
    "df1 = pd.DataFrame(df1.tolist(), df1.index, columns = ['failed_catches', 'num_failed','lazy_responder','repeat_offender'])\n",
    "\n",
    "K_responses = pd.concat([K_responses, df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat the response data to only include values from ['Not At All', ..., 'Extremely']\n",
    "value_list = [json.loads(dic)['typicality'] for dic in K_responses.responses.values]\n",
    "K_responses = K_responses.assign(ratings = value_list)\n",
    "\n",
    "# drop unneccesary columns and drop empty ratings\n",
    "K_responses = K_responses.drop(columns=['devMode', 'preamble', 'required', 'questions', \n",
    "                                        'randomize_question_order', 'scale_width', 'button_label', 'responses',\n",
    "                                        'question_order', 'trial_type', 'internal_node_id'])\n",
    "K_responses['ratings'] = K_responses['ratings'].replace('', np.nan)\n",
    "K_responses = K_responses.dropna(subset=['ratings'])\n",
    "\n",
    "di = {\"Not At All\": -2, \"Somewhat\": -1, \"Moderately\": 0, \"Very\": 1, \"Extremely\": 2}\n",
    "K_responses['enumerated_ratings'] = K_responses['ratings'].map(lambda x: di[x])\n",
    "\n",
    "# if a participant has more than 136 trials, find the gameID which has 136 entries and just use the trials from that gameID\n",
    "for pid in K_responses.prolificID.unique():\n",
    "    if K_responses[K_responses.prolificID == pid].shape[0] != 136:\n",
    "        subset = K_responses[K_responses.prolificID == pid]\n",
    "        for gid in subset.gameID.unique():\n",
    "            if subset[subset.gameID == gid].shape[0] == 136:\n",
    "                K_responses = K_responses[K_responses.prolificID != pid].append(subset[subset.gameID == gid], \n",
    "                                                                                ignore_index = True)\n",
    "\n",
    "# merge catch trial and main trial URLs\n",
    "K_responses = K_responses.sort_values('img_id')\n",
    "K_responses['img_id'] = K_responses['img_id'].fillna(K_responses['img_url'])\n",
    "K_responses = K_responses.reset_index(drop=True).drop(columns=['img_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some trials (batch 0) were encoding the 'enumerated ratings' values wrong. this code fixes it\n",
    "\n",
    "catch_trials = {'stimuli/catch_trials/0_ford_truck.jpg':[1,2], 'stimuli/catch_trials/1_german_shepherd.jpg':[1,2], \n",
    "                'stimuli/catch_trials/2_oddtruck.jpg':[-2,-1], 'stimuli/catch_trials/3_bedlington_terrier.jpg':[-2,-1], \n",
    "                'stimuli/catch_trials/4_pickup_truck.jpg':[1,2], 'stimuli/catch_trials/5_wierd_dog.jpg':[-2,-1], \n",
    "                'stimuli/catch_trials/6_wierdtruck.jpg':[-2,-1], 'stimuli/catch_trials/7_golden_retriever.jpg':[1,2]}\n",
    "for i in K_responses.prolificID.unique():\n",
    "    ppt_sub = K_responses[K_responses.prolificID == i]\n",
    "    counter = 0\n",
    "    for key, values in catch_trials.items():\n",
    "        if ppt_sub[ppt_sub.img_id == key]['enumerated_ratings'].values[0] not in values:\n",
    "            counter += 1\n",
    "    K_responses.loc[(K_responses.prolificID == i), 'num_failed'] = counter\n",
    "    if counter >= 4:\n",
    "        K_responses.loc[(K_responses.prolificID == i), 'failed_catches'] = True\n",
    "    else:\n",
    "        K_responses.loc[(K_responses.prolificID == i), 'failed_catches'] = False\n",
    "x=K_responses.groupby('prolificID')[['num_failed', 'failed_catches', 'repeat_offender']].mean()\n",
    "# drop participants who failed either catch trials or repeat_offender\n",
    "K_responses = K_responses[(K_responses.failed_catches == False) & (K_responses.repeat_offender == False)]\n",
    "K_responses.shape, int(K_responses.shape[0]/136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a dictionary with key: prolificID, value: subset of K_responses corresponding to that prolificID\n",
    "b = {k: v for (k, v) in K_responses.groupby('prolificID')}\n",
    "keys = list(b.keys())\n",
    "\n",
    "# get just the enumerated ratings in the form of a 2D numpy array\n",
    "list_ = []\n",
    "for i in keys:\n",
    "    list_.append(b[i].enumerated_ratings.values)\n",
    "participant_ratings = np.stack(list_, axis=0)\n",
    "\n",
    "corr_ratings = pd.DataFrame(data = np.corrcoef(participant_ratings), columns = keys, index = keys)\n",
    "euc_ratings = pd.DataFrame(squareform(pdist(participant_ratings,metric='euclidean')),columns=keys,index=keys)\n",
    "cos_ratings = pd.DataFrame(squareform(pdist(participant_ratings,metric='cosine')),columns=keys,index=keys)\n",
    "corr_vals = corr_ratings.mean().values\n",
    "euc_values = euc_ratings.mean().values\n",
    "cos_values = cos_ratings.mean().values\n",
    "\n",
    "corr_vals_adj = np.abs(corr_vals - np.median(corr_vals))/(1/len(corr_vals)*sum(np.abs(corr_vals - np.mean(corr_vals))))\n",
    "euc_values_adj = np.abs(euc_values - np.median(euc_values))/(1/len(euc_values)*sum(np.abs(euc_values - np.mean(euc_values))))\n",
    "cos_values_adj = np.abs(cos_values - np.median(cos_values))/(1/len(cos_values)*sum(np.abs(cos_values - np.mean(cos_values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop values whose adjusted correlation z-scores are greater than 3 on any of the three distance/correlation metrics\n",
    "tooDissimilar = dict(zip(corr_ratings.mean().index.values, \n",
    "                        (corr_vals_adj >= 3) | (euc_values_adj >= 3) | (cos_values_adj >= 3)))\n",
    "K_responses['tooDissimilar'] = K_responses['prolificID'].map(tooDissimilar)\n",
    "K_responses = K_responses[K_responses.tooDissimilar == False]\n",
    "K_responses.shape, int(K_responses.shape[0]/136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_responses.groupby('batch_num')['prolificID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_ratings, square=True)\n",
    "plt.title('pairwise correlation between responses of two participants');\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(euc_ratings, square=True);\n",
    "plt.title('euclidean distance between responses of two participants');\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cos_ratings, square=True);\n",
    "plt.title('cosine distance between responses of two participants');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(corr_vals_adj)\n",
    "plt.xlabel('mean correlation coefficient, adjusted')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of adjusted mean correlations for each participant');\n",
    "plt.show()\n",
    "\n",
    "plt.hist(euc_values_adj)\n",
    "plt.xlabel('mean euclidean distance, adjusted')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of adjusted mean euclidean distances for each participant');\n",
    "plt.show()\n",
    "\n",
    "plt.hist(cos_values_adj)\n",
    "plt.xlabel('mean cosine distance, adjusted')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of adjusted mean cosine distances for each participant');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the distribution of the norming data look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,4)) \n",
    "\n",
    "sns.barplot(data=K_responses, \n",
    "            x='category', \n",
    "            y='enumerated_ratings', \n",
    "            order=K_responses.groupby('category').mean().sort_values('enumerated_ratings').index)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "          rotation_mode=\"anchor\");\n",
    "plt.xlabel('')\n",
    "plt.ylabel('enumerated rating')\n",
    "plt.title('ratings for each category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_responses.groupby('category').mean().sort_values('enumerated_ratings').index.values[0+2:16+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_responses.groupby('category').mean().sort_values('enumerated_ratings').index.values[16+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order = [\"Not At All\", \"Somewhat\", \"Moderately\", \"Very\", \"Extremely\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4)) \n",
    "\n",
    "sns.countplot(data=K_responses, x='ratings', order=order)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "          rotation_mode=\"anchor\");\n",
    "plt.title('number of ratings in each bin, after preprocessing');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(K_responses, col='prolificID', col_wrap=3, aspect=2)\n",
    "g.map(sns.countplot, \"ratings\", order=order, palette='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(K_responses, col='category', col_wrap=5, aspect=2)\n",
    "g.map(sns.countplot, \"ratings\", order=order, palette='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_responses.groupby('batch_num')['prolificID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot and save count plots for each category\n",
    "# note: does not divide the graph into 3x3 segments!\n",
    "\n",
    "from pylab import MaxNLocator\n",
    "\n",
    "#randcat = np.random.choice(K_responses.category.unique())\n",
    "for cat in K_responses.category.unique():\n",
    "    instdf = K_responses[K_responses.category == cat][['img_id', 'enumerated_ratings']].sort_values('enumerated_ratings')\n",
    "\n",
    "    gb_df = instdf.groupby([\"img_id\", \"enumerated_ratings\"]).size().reset_index(name = \"counts\")\n",
    "    gb_df.sort_values([\"img_id\", \"enumerated_ratings\", \"counts\"], ascending = True, inplace = True)\n",
    "    order = K_responses[K_responses.category == cat\n",
    "                       ].groupby('img_id')['enumerated_ratings'].mean().sort_values(ascending=False).index.values\n",
    "    colors = {i:np.random.random(3,) for i in order}\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize = (12, 6))\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    for x in order:\n",
    "\n",
    "        # get x and y values for each group\n",
    "        x_values = gb_df[gb_df[\"img_id\"] == x][\"img_id\"]\n",
    "        y_values = gb_df[gb_df[\"img_id\"] == x][\"enumerated_ratings\"]\n",
    "\n",
    "        # extract the size of each group to plot\n",
    "        size = gb_df[gb_df[\"img_id\"] == x][\"counts\"]\n",
    "\n",
    "        # extract the color for each group and covert it from rgb to hex\n",
    "        color = matplotlib.colors.rgb2hex(colors[x])\n",
    "\n",
    "        # plot the data\n",
    "        ax.scatter(x_values, y_values, s = size*50, alpha=1, cmap = colors)\n",
    "    ax.set_title(\"Count plot: \" + cat);\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    sns.pointplot(x='img_id', y='enumerated_ratings', data=instdf,\n",
    "                  ci=None, order=order, scale = .7, color='grey').set(xticklabels=[], \n",
    "                                                                      xlabel='unique image', ylabel='enumerated rating');\n",
    "    ax.get_yaxis().set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.savefig(os.path.join(ratings_dir, cat + '_ratings.pdf'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Note: it's possible we can split the typicality into 4 blocks for even number of images in each block<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split data into low/med/high typicality. In this case, it was split evenly within each category\n",
    "\n",
    "df = pd.DataFrame(K_responses[K_responses.catch_trial == False].\n",
    "                  groupby(['img_id', 'category'])['enumerated_ratings'].mean().sort_values())\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "low_typicality, med_typicality, high_typicality = [], [], []\n",
    "for name, group in df.groupby('category'):\n",
    "    sorted_vals = group.sort_values('enumerated_ratings')['img_id'].values\n",
    "    low, med, high = np.array_split(sorted_vals, 3) # note: this is not an even split -- 11/11/10\n",
    "    low_typicality.extend(low)\n",
    "    med_typicality.extend(med)\n",
    "    high_typicality.extend(high)\n",
    "    \n",
    "df.loc[(df.img_id.isin(low_typicality)), 'typicality'] = 'low'\n",
    "df.loc[(df.img_id.isin(med_typicality)), 'typicality'] = 'medium'\n",
    "df.loc[(df.img_id.isin(high_typicality)), 'typicality'] = 'high'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_responses.loc[(K_responses.img_id.isin(low_typicality)), 'typicality'] = 'low'\n",
    "K_responses.loc[(K_responses.img_id.isin(med_typicality)), 'typicality'] = 'medium'\n",
    "K_responses.loc[(K_responses.img_id.isin(high_typicality)), 'typicality'] = 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what if we also want to account for consistency?\n",
    "\n",
    "df2 = pd.DataFrame(K_responses[K_responses.catch_trial == False].\n",
    "                  groupby(['img_id', 'category'])['enumerated_ratings']\n",
    "                  .agg(['mean','var']))#.sort_values(by='enumerated_ratings'))\n",
    "df2.reset_index(inplace=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "x1,x2 = df2[['mean']].values, df2[['var']].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x1_scaled, x2_scaled = min_max_scaler.fit_transform(x1), min_max_scaler.fit_transform(x2)\n",
    "df2['mean_norm'] = x1_scaled\n",
    "df2['var_norm'] = x2_scaled\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'lower rater agreement counts against typicality'\n",
    "a = 0.75\n",
    "df2['rating_metric'] = ((a)*df2['mean_norm'] - (1-a)*df2['var_norm'])\n",
    "df2.sort_values('rating_metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br> \n",
    "### Generate galleries by typicality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reallyrun = False\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "if reallyrun: \n",
    "    for category in K_responses[K_responses.catch_trial == False].category.unique():\n",
    "        frame = K_responses[K_responses.category == category]\n",
    "        frame = frame.groupby('img_id', as_index=False\n",
    "                             )['enumerated_ratings'].mean().sort_values('enumerated_ratings', ascending=False)\n",
    "        fig = plt.figure(figsize=(16,8),frameon=False)\n",
    "        for i,path in enumerate(frame.img_id.values):\n",
    "            request.urlretrieve(path,'temp.png')\n",
    "            img = Image.open(\"temp.png\")\n",
    "            p = plt.subplot(4,8,i+1)\n",
    "            plt.imshow(img)\n",
    "            k = p.get_xaxis().set_ticklabels([])\n",
    "            k = p.get_yaxis().set_ticklabels([])\n",
    "            k = p.get_xaxis().set_ticks([])\n",
    "            k = p.get_yaxis().set_ticks([])\n",
    "            p.axis('off')\n",
    "        plt.savefig(os.path.join(stims_gallery_dir, category + '_sorted.pdf'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example of above\n",
    "\n",
    "fig = plt.figure(figsize=(16,8),frameon=False)\n",
    "for i,path in enumerate(K_responses[K_responses.category == 'cat'].img_id.unique()):\n",
    "    request.urlretrieve(path,'temp.png')\n",
    "    img = Image.open(\"temp.png\")\n",
    "    p = plt.subplot(4,8,i+1)\n",
    "    plt.imshow(img)\n",
    "    k = p.get_xaxis().set_ticklabels([])\n",
    "    k = p.get_yaxis().set_ticklabels([])\n",
    "    k = p.get_xaxis().set_ticks([])\n",
    "    k = p.get_yaxis().set_ticks([])\n",
    "    p.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get list of object paths\n",
    "categories = K_responses[K_responses.catch_trial == False].category.unique()\n",
    "cat_paths = [os.path.join(typ_stims_dir,cat) for cat in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8,16),frameon=False)\n",
    "for i,f in enumerate(close_paths):\n",
    "    im = Image.open(f)\n",
    "    p = plt.subplot(8,4,i+1)\n",
    "    plt.imshow(im)\n",
    "    k = p.get_xaxis().set_ticklabels([])\n",
    "    k = p.get_yaxis().set_ticklabels([])\n",
    "    k = p.get_xaxis().set_ticks([])\n",
    "    k = p.get_yaxis().set_ticks([])\n",
    "    p.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_responses_batch0 = coll.find({'iterationName':iterationName, \n",
    "            'prolificID': {'$exists' : True, '$nin' : ['5f6d4203b5f3c71c3d5ec60f']},\n",
    "            'studyID': {'$exists' : True},\n",
    "            'sessionID': {'$exists' : True},\n",
    "            'eventType': 'rating-task'\n",
    "})\n",
    "K_responses_batch0 = pd.DataFrame(K_responses_batch0)\n",
    "K_responses_batch0 = K_responses_batch0[K_responses_batch0.batch_num == 0]\n",
    "\n",
    "K_flags_batch0 = coll.find({'prolificID': {'$exists' : True, '$nin' : ['5f6d4203b5f3c71c3d5ec60f', None]},\n",
    "            'studyID': {'$exists' : True},\n",
    "            'sessionID': {'$exists' : True},\n",
    "            'eventType': 'trial-catches',\n",
    "            'batch_num': {'$exists': False}\n",
    "})\n",
    "K_flags_batch0 = pd.DataFrame(K_flags_batch0)\n",
    "\n",
    "# manually check if these are the right participants\n",
    "a = ['5e8f7954d8c35926fb501f63', '5f7f8e2dfb4b2614748ffd3d', '5bc461db0b03740001230617', '5f3f2ef63ab8fa227e630d26', \n",
    "'5e1c9ecfcd8c4e01296e052d', '5f723cf881f5c0159cfa6da1', '5ba863a346de410001ecfb2a', '5f7fc54f6566cd19895017ea',\n",
    "'5f7fb2676397a318ad5688fd', '5f7fc36718e5dc19dc1058ca'].sort() \n",
    "b = list(K_flags_batch0.prolificID.values).sort() \n",
    "\n",
    "# assign batch num \n",
    "K_flags_batch0 = K_flags_batch0.assign(batch_num = 0)\n",
    "\n",
    "# make map from prolificID to flags and use map to extend to K_responses\n",
    "id_to_flags = dict(zip(K_flags_batch0['prolificID'].values, K_flags_batch0[['failed_catches', 'num_failed','lazy_responder','repeat_offender']].values.tolist()))\n",
    "\n",
    "df1 = K_responses_batch0['prolificID'].map(id_to_flags)\n",
    "df1 = pd.DataFrame(df1.tolist(), df1.index, columns = ['failed_catches', 'num_failed','lazy_responder','repeat_offender'])\n",
    "\n",
    "K_responses_batch0 = pd.concat([K_responses_batch0, df1], axis=1)\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat the response data to only include values from ['Very Poor', ..., 'Very Well']\n",
    "value_list = []\n",
    "for dic in K_responses_batch0.responses.values:\n",
    "    value_list.append(json.loads(dic)['typicality'])\n",
    "K_responses_batch0 = K_responses_batch0.assign(ratings = value_list)\n",
    "\n",
    "\n",
    "# drop unneccesary columns and drop empty ratings\n",
    "K_responses_batch0 = K_responses_batch0.drop(columns=['devMode', 'preamble', 'required', 'questions', \n",
    "                            'randomize_question_order', 'scale_width', 'button_label', 'responses',\n",
    "                            'question_order', 'trial_type', 'internal_node_id'])\n",
    "K_responses_batch0['ratings'] = K_responses_batch0['ratings'].replace('', np.nan)\n",
    "K_responses_batch0 = K_responses_batch0.dropna(subset=['ratings'])\n",
    "\n",
    "di = {\"Not At All\": -2, \"Somewhat\": -1, \"Moderately\": 0, \"Very\": 1, \"Extremely\": 2}\n",
    "K_responses_batch0['enumerated_ratings'] = K_responses_batch0['ratings'].map(lambda x: di[x])\n",
    "\n",
    "# merge catch trials and main trials\n",
    "K_responses_batch0 = K_responses_batch0.sort_values('img_id')\n",
    "K_responses_batch0['img_id'] = K_responses_batch0['img_id'].fillna(K_responses_batch0['img_url'])\n",
    "K_responses_batch0 = K_responses_batch0.reset_index(drop=True).drop(columns=['img_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ad2f = K_responses_batch0[K_responses_batch0.prolificID == '5bc461db0b03740001230617']\n",
    "dup_indices = ad2f.loc[ad2f.duplicated(subset='img_id', keep=False)].index\n",
    "duplicates = K_responses_batch0.iloc[dup_indices].reset_index(drop=True)\n",
    "np_duplicates = np.reshape(duplicates['enumerated_ratings'].values, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identical response\n",
    "print(sum([i[0] == i[1] for i in np_duplicates]))\n",
    "\n",
    "# 1 off from identical response\n",
    "print(sum([i[0] in range(i[1] - 1, i[1] + 2) for i in np_duplicates]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix duplicate indices from that one participant\n",
    "adf = K_responses_batch0[K_responses_batch0.prolificID == '5bc461db0b03740001230617']\n",
    "dup_indices = adf.loc[adf.duplicated(subset='img_id', keep='last')].index\n",
    "K_responses_batch0 = K_responses_batch0.drop(dup_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### How many people are picking the same rating per image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "arr2 = []\n",
    "for img in np.delete(K_responses_batch0.img_id.unique(), 17):    # there is a random nan value at index 17\n",
    "    tmpa = K_responses_batch0[(K_responses_batch0.img_id == img) & (K_responses_batch0.failed_catches == True)]\n",
    "    tmpb = K_responses_batch0[(K_responses_batch0.img_id == img) & (K_responses_batch0.failed_catches == False)]\n",
    "    tmpc = mode(K_responses_batch0[K_responses_batch0.img_id == img]['enumerated_ratings'])[0][0]\n",
    "    a = mode(tmpa['enumerated_ratings'])[1][0]/5   # 5 people failed, 5 people did not\n",
    "    b = mode(tmpb['enumerated_ratings'])[1][0]/5\n",
    "    a2 = tmpa[tmpa.enumerated_ratings == tmpc]['enumerated_ratings'].count()/5\n",
    "    b2 = tmpb[tmpb.enumerated_ratings == tmpc]['enumerated_ratings'].count()/5\n",
    "    arr.append([a,b])\n",
    "    arr2.append([a2,b2])\n",
    "arr = np.asarray(arr)\n",
    "arr2 = np.asarray(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what proportion of participants picked the modal response for each image?\n",
    "sns.distplot(arr[:,0], hist=False, rug=True, label='failed')\n",
    "sns.distplot(arr[:,1], hist=False, rug=True, label='did not fail');\n",
    "plt.xlabel('proportion of participants who shared the same response in a given image');\n",
    "plt.title('mode calculated separately for for each image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(arr2[:,0], hist=False, rug=True, label='failed')\n",
    "sns.distplot(arr2[:,1], hist=False, rug=True, label='did not fail');\n",
    "plt.xlabel('proportion of participants who shared the same response in a given image');\n",
    "plt.title('combined mode between both types for each image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(K_responses_batch0[K_responses_batch0.failed_catches == True]['enumerated_ratings'], label='failed');\n",
    "sns.distplot(K_responses_batch0[K_responses_batch0.failed_catches == False]['enumerated_ratings'], label='did not fail')\n",
    "plt.legend();\n",
    "plt.title('distribution of ratings between those who failed catch trials and those who did not');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How similar are different participants' responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compressed form: sims = [sum([ratings[i,k] == ratings[j,k] for k in range(ratings.shape[1])]) for i,j in combinations(range(10), 2)]\n",
    "\n",
    "def get_pairwise_similarity_matrix(ratings, distance = 0):\n",
    "    '''\n",
    "        ratings: a # participants x # images 2D numpy array\n",
    "        returns an upper triangular matrix that compares rating responses for participant i and participant j \n",
    "    '''\n",
    "    sims = []\n",
    "    # for each pair of participants,\n",
    "    for i,j in combinations(range(ratings.shape[0]), 2):\n",
    "        tmp = 0\n",
    "        # for each image,\n",
    "        for k in range(ratings.shape[1]):\n",
    "            # is participant j's rating 'distance' away from participant i's rating? \n",
    "            if distance != 0:\n",
    "                tmp += ratings[j,k] in range(ratings[i,k] - distance, ratings[i,k] + distance + 1) # +1 for inclusive upper bound\n",
    "            else:\n",
    "                tmp += ratings[j,k] == ratings[i,k]\n",
    "        sims.append(tmp)\n",
    "    \n",
    "    # turn it into upper triangular matrix\n",
    "    tri = np.zeros((ratings.shape[0], ratings.shape[0]))\n",
    "    tri[np.triu_indices(ratings.shape[0], 1)] = sims\n",
    "    \n",
    "    return tri/ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(K_responses_batch0[K_responses_batch0.catch_trial == True][['img_id','enumerated_ratings']].sort_values('img_id').values)\n",
    "\n",
    "#.groupby('img_id')['enumerated_ratings'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what specific images are the people who pass the catch trials missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a dictionary with key: prolificID, value: subset of K_responses_batch0 corresponding to that prolificID\n",
    "a = {k: v for (k, v) in K_responses_batch0.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "\n",
    "# get just the enumerated ratings in the form of a 2D numpy array\n",
    "participant_ratings = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "print('shape:', participant_ratings.shape)\n",
    "\n",
    "# get average correlation across all pairs of participants\n",
    "participant_ratings_noatypical = np.delete(participant_ratings, 2, 0)\n",
    "corrs = [np.corrcoef(participant_ratings_noatypical[i], participant_ratings_noatypical[j])[0,1] for i,j in combinations(range(9), 2)]\n",
    "a = np.asarray(corrs)\n",
    "print('average pairwise correlation across all participants, removing atypical one', a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up pass vs failed catch trials\n",
    "K_pass = K_responses_batch0[(K_responses_batch0.failed_catches == False) & (K_responses_batch0.prolificID != '5e1c9ecfcd8c4e01296e052d')]\n",
    "K_fail = K_responses_batch0[(K_responses_batch0.failed_catches == True)  & (K_responses_batch0.prolificID != '5e1c9ecfcd8c4e01296e052d')]\n",
    "\n",
    "# generate a dictionary with key: prolificID, value: subset of K_responses_batch0 corresponding to that prolificID\n",
    "a = {k: v for (k, v) in K_pass.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "# get just the enumerated ratings in the form of a 2D numpy array \n",
    "participant_ratings_pass_noatypical = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "\n",
    "# generate a dictionary with key: prolificID, value: subset of K_responses_batch0 corresponding to that prolificID\n",
    "a = {k: v for (k, v) in K_fail.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "# get just the enumerated ratings in the form of a 2D numpy array\n",
    "participant_ratings_fail_noatypical = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "print(\"passing vs failed participant responses shape:\",participant_ratings_pass_noatypical.shape, participant_ratings_fail_noatypical.shape)\n",
    "\n",
    "# compute average correlation for set who passed catch trials\n",
    "corrs = [np.corrcoef(participant_ratings_pass_noatypical[i], participant_ratings_pass_noatypical[j])[0,1] for i,j in combinations(range(participant_ratings_pass_noatypical.shape[0]), 2)]\n",
    "pass_corr = np.asarray(corrs)\n",
    "print('participants who passed catch trials, for all trials:', pass_corr.mean())\n",
    "\n",
    "# compute average correlation for set who failed catch trials\n",
    "corrs = [np.corrcoef(participant_ratings_fail_noatypical[i], participant_ratings_fail_noatypical[j])[0,1] for i,j in combinations(range(participant_ratings_fail_noatypical.shape[0]), 2)]\n",
    "fail_corr = np.asarray(corrs)\n",
    "print('participants who failed catch trials, for all trials:', fail_corr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- try between pass and fail, are their response vectors systematically different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up isCatchTrial x failedCatches 2x2 \n",
    "K_catch = K_responses_batch0[(K_responses_batch0.catch_trial == True) & (K_responses_batch0.prolificID != '5e1c9ecfcd8c4e01296e052d')]\n",
    "K_main = K_responses_batch0[(K_responses_batch0.catch_trial == False) & (K_responses_batch0.prolificID != '5e1c9ecfcd8c4e01296e052d')]\n",
    "\n",
    "K_catch_pass = K_catch[K_catch.failed_catches == False]\n",
    "K_catch_fail = K_catch[K_catch.failed_catches == True]\n",
    "K_main_pass = K_main[K_main.failed_catches == False]\n",
    "K_main_fail = K_main[K_main.failed_catches == True]\n",
    "print('dataframe shapes:', K_catch_pass.shape, K_catch_fail.shape, K_main_pass.shape, K_main_fail.shape)\n",
    "\n",
    "# extract ratings only as 2D numpy array for 2x2 set\n",
    "a = {k: v for (k, v) in K_catch_pass.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "participant_ratings_catch_pass = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "\n",
    "a = {k: v for (k, v) in K_catch_fail.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "participant_ratings_catch_fail = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "\n",
    "a = {k: v for (k, v) in K_main_pass.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "participant_ratings_main_pass = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "\n",
    "a = {k: v for (k, v) in K_main_fail.groupby('prolificID')}\n",
    "keys = list(a.keys())\n",
    "participant_ratings_main_fail = np.stack([a[i].enumerated_ratings.values for i in keys], axis=0)\n",
    "\n",
    "print('2D numpy shapes', participant_ratings_catch_pass.shape, participant_ratings_catch_fail.shape, participant_ratings_main_pass.shape, participant_ratings_main_fail.shape)\n",
    "\n",
    "# get average correlation for for the 2x2 set\n",
    "corrs = [np.corrcoef(participant_ratings_catch_pass[i], participant_ratings_catch_pass[j])[0,1] for i,j in combinations(range(participant_ratings_catch_pass.shape[0]), 2)]\n",
    "catch_pass_corr = np.asarray(corrs)\n",
    "print('catch trials only, passing participants:', catch_pass_corr.mean())\n",
    "\n",
    "corrs = [np.corrcoef(participant_ratings_catch_fail[i], participant_ratings_catch_fail[j])[0,1] for i,j in combinations(range(participant_ratings_catch_fail.shape[0]), 2)]\n",
    "catch_fail_corr = np.asarray(corrs)\n",
    "print('catch trials only, failing participants:', catch_fail_corr.mean())\n",
    "\n",
    "corrs = [np.corrcoef(participant_ratings_main_pass[i], participant_ratings_main_pass[j])[0,1] for i,j in combinations(range(participant_ratings_main_pass.shape[0]), 2)]\n",
    "main_pass_corr = np.asarray(corrs)\n",
    "print('no catch trials, passing participants:', main_pass_corr.mean())\n",
    "\n",
    "corrs = [np.corrcoef(participant_ratings_main_fail[i], participant_ratings_main_fail[j])[0,1] for i,j in combinations(range(participant_ratings_main_fail.shape[0]), 2)]\n",
    "main_fail_corr = np.asarray(corrs)\n",
    "print('no catch trials, failing participants:', main_fail_corr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a dictionary with key: prolificID, value: subset of K_responses_batch0 corresponding to that prolificID\n",
    "b = {k: v for (k, v) in K_responses_batch0[K_responses_batch0.failed_catches == True].groupby('prolificID')}\n",
    "keys = list(b.keys())\n",
    "\n",
    "# get just the enumerated ratings in the form of a 2D numpy array\n",
    "list_ = []\n",
    "for i in keys:\n",
    "    list_.append(b[i].enumerated_ratings.values)\n",
    "participant_ratings_failed = np.stack(list_, axis=0)\n",
    "\n",
    "# generate a dictionary with key: prolificID, value: subset of K_responses_batch0 corresponding to that prolificID\n",
    "c = {k: v for (k, v) in K_responses_batch0[K_responses_batch0.failed_catches == False].groupby('prolificID')}\n",
    "keys = list(c.keys())\n",
    "\n",
    "# get just the enumerated ratings in the form of a 2D numpy array\n",
    "list_ = []\n",
    "for i in keys:\n",
    "    list_.append(c[i].enumerated_ratings.values)\n",
    "participant_ratings_passed = np.stack(list_, axis=0)\n",
    "participant_ratings_failed.shape, participant_ratings_passed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# simulate the expected standard deviation of 10 people guessing at random\n",
    "print('chance std. dev (passed):', statistics.mean([statistics.pstdev(random.choices([-2,-1,0,1,2], k=4)) for i in range(10000)]))\n",
    "# get the mean standard deviation of ratings within each image, where the range of standard deviations possible is [0,2]\n",
    "print('actual std. dev (passed):', statistics.mean([participant_ratings_passed[:, i].std() for i in range(136)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simulate the expected standard deviation of 10 people guessing at random\n",
    "print('chance std. dev (failed):', statistics.mean([statistics.pstdev(random.choices([-2,-1,0,1,2], k=6)) for i in range(10000)]))\n",
    "# get the mean standard deviation of ratings within each image, where the range of standard deviations possible is [0,2]\n",
    "print('actual std. dev (failed):', statistics.mean([participant_ratings_failed[:, i].std() for i in range(136)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simulate the expected standard deviation of 10 people guessing at random\n",
    "print('chance std. dev:', statistics.mean([statistics.pstdev(random.choices([-2,-1,0,1,2], k=10)) for i in range(10000)]))\n",
    "\n",
    "# get the mean standard deviation of ratings within each image, where the range of standard deviations possible is [0,2]\n",
    "print('actual std. dev:', statistics.mean([participant_ratings[:, i].std() for i in range(136)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings_passed, 0)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims, vmax = 0.5)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of identical responses between two participants (passed)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings_failed, 0)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims, vmax = 0.5)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of identical responses between two participants (failed)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings, 0)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of identical responses between two participants');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "22/60\n",
    "sims[sims != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings, 1)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of responses off by 1 between two participants');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "49/60, sims[sims != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings, 2)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of responses off by 2 between two participants');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings, 3)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of responses off by 3 between two participants');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings, 4)\n",
    "\n",
    "# plot results\n",
    "sns.heatmap(sims)\n",
    "plt.xlabel('participant index')\n",
    "plt.ylabel('participant index')\n",
    "plt.title('proportion of responses off by 4 between two participants');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from nltk import agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formatted_codes = [[index, index2, rating] for index, ppt in enumerate(participant_ratings.tolist()) for index2, rating in enumerate(ppt)]\n",
    "formatted_codes_passed = [[index, index2, rating] for index, ppt in enumerate(participant_ratings_passed.tolist()) for index2, rating in enumerate(ppt)]\n",
    "formatted_codes_failed = [[index, index2, rating] for index, ppt in enumerate(participant_ratings_failed.tolist()) for index2, rating in enumerate(ppt)]\n",
    "\n",
    "\n",
    "len(formatted_codes), len(formatted_codes_passed), len(formatted_codes_failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some pretty low scores! <br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look for a rejection criteria for counteracting people who guess/select one thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum(ind_count)\n",
    "#[i*sum(ind_count) for i in pop_prop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for mini in K_responses.batch_num.unique():\n",
    "    miniset = K_responses[K_responses.batch_num == mini]\n",
    "    for ppt in miniset.prolificID.unique():\n",
    "        pop = miniset[miniset.prolificID != ppt].ratings.values\n",
    "        ind = miniset[miniset.prolificID == ppt].ratings.values\n",
    "\n",
    "        frequency_pop, frequency_ind = {}, {}\n",
    "        for item in np.unique(pop).tolist():\n",
    "            frequency_pop[item] = pop.tolist().count(item)\n",
    "            frequency_ind[item] = ind.tolist().count(item)\n",
    "        ind_count = list(frequency_ind.values())\n",
    "        pop_count = list(frequency_pop.values())\n",
    "        pop_prop = [i/sum(pop_count) for i in pop_count]\n",
    "\n",
    "        expected_adj = [i*sum(ind_count) for i in pop_prop]\n",
    "\n",
    "        res[ppt] = chisquare(f_obs=ind_count, f_exp=expected_adj)[0:2]\n",
    "[i[1] for i in list(res.values())]\n",
    "sum([i[1]<0.01 for i in list(res.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for ppt in K_responses.prolificID.unique():\n",
    "    pop = K_responses[K_responses.prolificID != ppt].ratings.values\n",
    "    ind = K_responses[K_responses.prolificID == ppt].ratings.values\n",
    "    \n",
    "    frequency_pop, frequency_ind = {}, {}\n",
    "    for item in np.unique(pop).tolist():\n",
    "        frequency_pop[item] = pop.tolist().count(item)\n",
    "        frequency_ind[item] = ind.tolist().count(item)\n",
    "    ind_count = list(frequency_ind.values())\n",
    "    pop_count = list(frequency_pop.values())\n",
    "    pop_prop = [i/sum(pop_count) for i in pop_count]\n",
    "    \n",
    "    expected_adj = [i*sum(ind_count) for i in pop_prop]\n",
    "    \n",
    "    res[ppt] = chisquare(f_obs=ind_count, f_exp=expected_adj)[0:2]\n",
    "sum([i[1]<0.01 for i in list(res.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "myList = defaultdict(list)\n",
    "[myList[key] for key in K_responses.prolificID.unique()]\n",
    "myList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppt_vals = dict([(i,[]) for i in K_responses.prolificID.unique().tolist()])\n",
    "\n",
    "for img in K_responses.img_id.unique():\n",
    "    imgset = K_responses[K_responses.img_id == img]\n",
    "    for ppt in imgset.prolificID.unique():\n",
    "        ind_rating = imgset[imgset.prolificID == ppt].enumerated_ratings.values[0]\n",
    "\n",
    "        # for this specific image, is this participant's response near the mean response?\n",
    "        mean_ratings = imgset.enumerated_ratings.mean()\n",
    "        ppt_vals[ppt].append(floor(mean_ratings) <= ind_rating \n",
    "                             <= ceil(mean_ratings))\n",
    "\n",
    "sns.distplot([sum(ppt_vals[i]) for i in ppt_vals.keys()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppt_vals = dict([(i,[]) for i in K_responses.prolificID.unique().tolist()])\n",
    "\n",
    "for img in K_responses.img_id.unique():\n",
    "    imgset = K_responses[K_responses.img_id == img]\n",
    "    for ppt in imgset.prolificID.unique():\n",
    "        ind_rating = imgset[imgset.prolificID == ppt].enumerated_ratings.values[0]\n",
    "        \n",
    "        # for this specific image, is this participant's response the modal response?\n",
    "        ppt_vals[ppt].append(mode(imgset.enumerated_ratings.values)[0][0] == ind_rating)\n",
    "\n",
    "sns.distplot([sum(ppt_vals[i]) for i in ppt_vals.keys()])\n",
    "[sum(ppt_vals[i]) for i in ppt_vals.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.histogram([sum(ppt_vals[i]) for i in ppt_vals.keys()])\n",
    "plt.hist([sum(ppt_vals[i]) for i in ppt_vals.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppt_vals = dict([(i,[]) for i in K_responses.prolificID.unique().tolist()])\n",
    "\n",
    "for img in K_responses.img_id.unique():\n",
    "    imgset = K_responses[K_responses.img_id == img]\n",
    "    for ppt in imgset.prolificID.unique():\n",
    "        ind_rating = imgset[imgset.prolificID == ppt].enumerated_ratings.values[0]\n",
    "        \n",
    "        # for this specific image, is this participant's response the modal response? Scaled by agreement\n",
    "        [ppt_vals[ppt].append(mode(imgset.enumerated_ratings.values)[0][0] == ind_rating) for i in range(mode(imgset.enumerated_ratings.values)[1][0])]\n",
    "\n",
    "sns.distplot([sum(ppt_vals[i]) for i in ppt_vals.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist([sum(ppt_vals[i]) for i in ppt_vals.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "th = np.asarray([[i, sum(ppt_vals[i])] for i in ppt_vals.keys()])\n",
    "th = th[th[:,0].argsort()][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a dictionary with key: prolificID, value: subset of K_responses corresponding to that prolificID\n",
    "b = {k: v for (k, v) in K_responses.groupby('prolificID')}\n",
    "keys = list(b.keys())\n",
    "\n",
    "# get just the enumerated ratings in the form of a 2D numpy array\n",
    "list_ = []\n",
    "for i in keys:\n",
    "    list_.append(b[i].enumerated_ratings.values)\n",
    "participant_ratings = np.stack(list_, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of identical responses for all combinations of participants\n",
    "sims = get_pairwise_similarity_matrix(participant_ratings, 0)\n",
    "mask = np.zeros_like(sims)\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "\n",
    "\n",
    "# plot results\n",
    "fig, ax = plt.subplots(figsize=(12,10)) \n",
    "sns.heatmap(sims, square=True, ax=ax,mask=mask,  cbar_kws={\"shrink\": .5}, rasterized=False)\n",
    "ax.set_xticklabels(th, rotation=90)\n",
    "ax.set_yticklabels(th)\n",
    "\n",
    "# ax2 = fig.add_subplot(111, label=\"secondary\")\n",
    "# ax2.set_aspect(\"equal\")\n",
    "# ax2.set_xlim(ax.get_xlim())\n",
    "# ax2.set_ylim(ax.get_ylim())\n",
    "# ax2.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False,\n",
    "#                 top=True, labeltop=True)\n",
    "# ax2.set_facecolor(\"none\")\n",
    "# for _, spine in ax2.spines.items():\n",
    "#     spine.set_visible(False)\n",
    "# ax2.set_xticks(ax.get_xticks())\n",
    "# ax2.set_xticklabels(keys, fontsize=13)\n",
    "# plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"left\",\n",
    "#          rotation_mode=\"anchor\")\n",
    "\n",
    "\n",
    "plt.xlabel('# of modal responses for this participant')\n",
    "plt.ylabel('# of modal responses for this participant')\n",
    "plt.title('number of identical responses between two participants');\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smh = np.asarray([np.append(sims[i, :], sims[:,i])[np.append(sims[i, :], sims[:,i]) != 0] for i in range(len(sims))])\n",
    "x,y = smh.mean(axis=1), th.astype(np.int)/136\n",
    "plt.plot(x, y, '.')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)\n",
    "plt.xlabel('average proportion of identical responses')\n",
    "plt.ylabel('proportion of modal ratings');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(K_responses[K_responses.prolificID == '5def907bd6c08d000a157a88']['enumerated_ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(euc_ratings.mean().values)\n",
    "plt.xlabel('mean euclidean distance')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of euclidean distances for each participant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(cos_ratings.mean().values)\n",
    "plt.xlabel('mean cosine distance')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of cosine distances for each participant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(corr_ratings.mean().values)\n",
    "plt.xlabel('mean correlation coefficient')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of mean correlations for each participant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(euc_ratings.mean().values)\n",
    "plt.xlabel('mean euclidean distance')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of euclidean distances for each participant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(cos_ratings.mean().values)\n",
    "plt.xlabel('mean cosine distance')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of cosine distances for each participant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(corr_ratings.mean().values)\n",
    "plt.xlabel('mean correlation coefficient')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('distribution of mean correlations for each participant');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(K_responses[K_responses.prolificID == '5def907bd6c08d000a157a88'].enumerated_ratings.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(K_responses[K_responses.prolificID == '5f6b0d716f590a1ea96a2c42'].enumerated_ratings.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(K_responses[K_responses.prolificID == '5eb7ace91de6e86e9a6053d2'].enumerated_ratings.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_responses.groupby('prolificID')['enumerated_ratings'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_freqs[1]/response_freqs[1].sum(),response_freqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.choice(list(response_freqs.keys()), size=136, p=list(response_freqs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simulation of our trial according to current response frequencies \n",
    "from itertools import groupby\n",
    "import heapq\n",
    "\n",
    "response_freqs = np.unique(K_responses.enumerated_ratings.values, return_counts=True)\n",
    "response_freqs = dict(zip(response_freqs[0],response_freqs[1]/response_freqs[1].sum()))\n",
    "\n",
    "def generate_consecutives():\n",
    "    randresps = np.random.choice(list(response_freqs.keys()), size=136, p=list(response_freqs.values()))\n",
    "    return heapq.nlargest(2, (len(list(y)) for (c,y) in groupby(randresps)))\n",
    "\n",
    "arr = np.asarray([generate_consecutives() for i in range(10000)])\n",
    "sum((arr[:,0] >= 20) | ((arr[:,0] >= 10) & (arr[:,1] >= 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum((arr[:,0] >= 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_flags.lazy_responder.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_L = [(k, sum(1 for i in g)) for k,g in groupby(randresps)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_ratings.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first pilot of 10 participants on prolific, they were recorded in the iterationName 'development'\n",
    "\n",
    "With 136 trials and 2 exit survey trials, there will be up to 10 * (136 + 2) = 1380 trials\n",
    "\n",
    "The code to extract information from those participants follows below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_pilot = coll.find({'iterationName':'development', \n",
    "                     'prolificID': {'$exists' : True, '$nin' : ['5f6d4203b5f3c71c3d5ec60f', None]},\n",
    "                     'studyID': {'$exists' : True},\n",
    "                     'sessionID': {'$exists' : True}})\n",
    "K_pilot = pd.DataFrame(k_pilot)\n",
    "K_pilot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: there are 1379 entries because one participant did not fill in the survey-text trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate into response trials and exit survey trials\n",
    "K_responses_pilot = K_pilot[K_pilot['eventType'] == 'rating-task']\n",
    "K_survey_pilot = K_pilot[K_pilot['eventType'] == 'survey']\n",
    "\n",
    "K_responses = pd.DataFrame()\n",
    "K_survey = pd.DataFrame()\n",
    "K_flags = K[~pd.isna(K['num_failed'])]\n",
    "\n",
    "K_responses = K_responses.append(K_responses_pilot)\n",
    "K_survey = K_survey.append(K_survey_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat the response data to only include values from ['Very Poor', ..., 'Very Well']\n",
    "value_list = []\n",
    "for dic in K_responses.responses.values:\n",
    "    value_list.append(json.loads(dic)['typicality'])\n",
    "K_responses = K_responses.assign(ratings = value_list)\n",
    "\n",
    "# drop unneccesary columns and drop empty ratings\n",
    "K_responses = K_responses.drop(columns=['devMode', 'preamble', 'required', 'questions', \n",
    "                            'randomize_question_order', 'scale_width', 'button_label', 'responses',\n",
    "                            'question_order', 'trial_type', 'internal_node_id'])\n",
    "K_responses['ratings'] = K_responses['ratings'].replace('', np.nan)\n",
    "K_responses = K_responses.dropna(subset=['ratings'])\n",
    "\n",
    "di = {\"Not At All\": -2, \"Somewhat\": -1, \"Moderately\": 0, \"Very\": 1, \"Extremely\": 2}\n",
    "K_responses['enumerated_ratings'] = K_responses['ratings'].map(lambda x: di[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "order = [\"Not At All\", \"Somewhat\", \"Moderately\", \"Very\", \"Extremely\"]\n",
    "sns.countplot(K_responses['ratings'], palette='viridis', order=order);\n",
    "plt.xlabel('typicality rating');\n",
    "plt.title('counts of typicality ratings for current complete trials');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(K_responses, col='prolificID', col_wrap=2, aspect=2)\n",
    "g.map(sns.countplot, \"ratings\", order=order, palette='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(K_responses, col='category', col_wrap=5, aspect=2)\n",
    "g.map(sns.countplot, \"ratings\", order=order, palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
